{\rtf1\ansi\ansicpg1252\cocoartf1504
{\fonttbl\f0\fswiss\fcharset0 Helvetica;}
{\colortbl;\red255\green255\blue255;}
{\*\expandedcolortbl;\csgray\c100000;}
\margl1440\margr1440\vieww12540\viewh16140\viewkind1
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\partightenfactor0

\f0\fs28 \cf0 #!/usr/bin/env python2\
# -*- coding: utf-8 -*-\
"""\
Created on Sat Oct 29 22:00:35 2016\
\
@author: JKM\
"""\
\
import pandas as pd\
import requests\
import numpy as np\
import time\
from bs4 import BeautifulSoup as bs4\
\
url_base = 'https://washingtondc.craigslist.org/search/cta' \
params = dict(min_auto_year=2010, max_auto_miles=100000) \
rsp = requests.get(url_base, params=params)\
print(rsp.text[:1000])\
\
html = bs4(rsp.text, 'html.parser')\
print(html.prettify()[:2000])\
\
auto = html.find_all('p', attrs=\{'class': 'row'\})\
print(len(auto))\
\
this_auto = auto[1]\
print(this_auto.prettify())\
\
price = this_auto.findAll(attrs=\{'class': 'price'\})[0].text\
vehicle = this_auto.findAll(attrs=\{'class': 'hdrlnk'\})[0].text\
location = this_auto.findAll(attrs=\{'class': 'pnr'\})[0].text\
print('\\n'.join([str(i) for i in [price, vehicle, location]]))\
\
loc_prefixes = ['doc', 'nva', 'mid']\
\
def find_prices(results):\
    prices = []\
    for rw in results:\
        price = rw.find('span', \{'class': 'price'\})\
        if price is not None:\
            price = float(price.text.strip('$'))\
        else:\
            price = np.nan\
        prices.append(price)\
    return prices\
\
def find_times(results):\
    times = []\
    for rw in autos:\
        if time is not None:\
            date = time['datetime']\
            date = pd.to_datetime(date)\
        else:\
            date = np.nan\
        times.append(date)\
    return times\
    \
results = []  \
search_indices = np.arange(0, 300, 100)\
\
for loc in loc_prefixes:\
    print loc\
    time.sleep(5)\
    for i in search_indices:\
        url = 'https://washingtondc.craigslist.org/search/cta'.format(loc)\
        resp = requests.get(url, params=\{'min_auto_year': 2010, 'max_auto_miles': 100000, 's': i\})\
        txt = bs4(resp.text, 'html.parser')\
        autos = txt.findAll(attrs=\{'class': "row"\})\
\
        title = [rw.find('a', attrs=\{'class': 'hdrlnk'\}).text for rw in autos]\
        links = [rw.find('a', attrs=\{'class': 'hdrlnk'\})['href'] for rw in autos]\
        auto_id = [rw.find('a', attrs=\{'class': 'hdrlnk'\})['data-id'] for rw in autos]\
        date = [pd.to_datetime(rw.find('time')['datetime']) for rw in autos]\
        price = find_prices(autos)\
        \
        data = np.array([date, auto_id, price, title, links])\
        col_names = ['date', 'auto_id', 'price', 'title', 'links']\
        df = pd.DataFrame(data.T, columns=col_names)\
        df = df.set_index('date')\
        df['loc'] = loc\
\
        results.append(df)\
\
results = pd.concat(results, axis=0)\
\
results[['price']] = results[['price']].convert_objects(convert_numeric=True)\
\
results.head()\
\
df\
\
ax = results.hist('price', bins=np.arange(0, 10000, 100))[0, 0]\
ax.set_title('DC Metro Count Used Cars, Dist by Price', fontsize=20)\
ax.set_xlabel('Price', fontsize=18)\
ax.set_ylabel('Count', fontsize=18)\
\
import string\
use_chars = string.ascii_letters +\\\
    ''.join([str(i) for i in range(10)]) +\\\
    ' /\\.'\
results['title'] = results['title'].apply(\
    lambda a: ''.join([i for i in a if i in use_chars]))\
\
\
df.to_csv('/Users/newuser/Desktop/craigslist_results.csv')}